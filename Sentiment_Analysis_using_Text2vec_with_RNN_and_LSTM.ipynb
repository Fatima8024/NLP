{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwioC/6xZ7RcLq0agHtMQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1744ce07a6e6402090ad7ddf41a45850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b538cf1908534e09ba6453c29fb11270",
              "IPY_MODEL_283b17e8e3e84ed0ab433fe7755d66bf",
              "IPY_MODEL_e09a4bee6726402fbcfffc8bdb7a79b8"
            ],
            "layout": "IPY_MODEL_ff207cd773f14e8787258ffe3049b9cb"
          }
        },
        "b538cf1908534e09ba6453c29fb11270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be81f1968284ad2bf145d3d6619cd39",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2bb79a81c348adbd429546e7c3ed21",
            "value": "config.json: 100%"
          }
        },
        "283b17e8e3e84ed0ab433fe7755d66bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ee8c40b1434e26a4990fe275ae27d5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac081129468f471cba012d580d14c4ef",
            "value": 570
          }
        },
        "e09a4bee6726402fbcfffc8bdb7a79b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97550feb8c454f4ab335fee532acdc6b",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9a2c08f45b452ea7d27703d96c5f19",
            "value": " 570/570 [00:00&lt;00:00, 33.6kB/s]"
          }
        },
        "ff207cd773f14e8787258ffe3049b9cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be81f1968284ad2bf145d3d6619cd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2bb79a81c348adbd429546e7c3ed21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ee8c40b1434e26a4990fe275ae27d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac081129468f471cba012d580d14c4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97550feb8c454f4ab335fee532acdc6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9a2c08f45b452ea7d27703d96c5f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c4863b25034c0db01112fe004c21d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9875dafa47794f19b3188555259bb907",
              "IPY_MODEL_fb8f8459721a484f9879f1c1ab815f7b",
              "IPY_MODEL_d0a18f97b6d341d081cd16a163d46a25"
            ],
            "layout": "IPY_MODEL_ef6625ea313d43c89a2625c00c34ae9e"
          }
        },
        "9875dafa47794f19b3188555259bb907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a5db8800ce4e21a2d78124b75e7004",
            "placeholder": "​",
            "style": "IPY_MODEL_55294642c02241d69b039d823b243b23",
            "value": "model.safetensors: 100%"
          }
        },
        "fb8f8459721a484f9879f1c1ab815f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e9c5b48c9c434bb45f9604440ab3d9",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16b4a8ba3e064484beacf36c263a069f",
            "value": 440449768
          }
        },
        "d0a18f97b6d341d081cd16a163d46a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6177dc39910b485e8774efc3ff6e0457",
            "placeholder": "​",
            "style": "IPY_MODEL_3752018d46cf4bf5b21cd13333ef4a8b",
            "value": " 440M/440M [00:02&lt;00:00, 231MB/s]"
          }
        },
        "ef6625ea313d43c89a2625c00c34ae9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a5db8800ce4e21a2d78124b75e7004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55294642c02241d69b039d823b243b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e9c5b48c9c434bb45f9604440ab3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b4a8ba3e064484beacf36c263a069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6177dc39910b485e8774efc3ff6e0457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3752018d46cf4bf5b21cd13333ef4a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5256c550acb4786931016a45f58d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_422ce2c139dc479c8337e8d1ede4dd0d",
              "IPY_MODEL_6f98cd4b5e794771a1ab0aebf5d4ca74",
              "IPY_MODEL_f90e0f100eeb4bbe896252e46c8f3c37"
            ],
            "layout": "IPY_MODEL_7ad5e22fd1ef4a2aa51811bfb76ee3e2"
          }
        },
        "422ce2c139dc479c8337e8d1ede4dd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05776a29225e4b2f8e9473f3fa818961",
            "placeholder": "​",
            "style": "IPY_MODEL_6b69c54d2d1b4214a2c527f7a023ac82",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6f98cd4b5e794771a1ab0aebf5d4ca74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f631b9534c46529d87899b4b952564",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82d5eab5df4a43b583b87c1b61fd4b5d",
            "value": 48
          }
        },
        "f90e0f100eeb4bbe896252e46c8f3c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5455da1593bd4b83affe37495bf8e4d1",
            "placeholder": "​",
            "style": "IPY_MODEL_51eca6f23ef7416baeb3ca8a029b3ad9",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.66kB/s]"
          }
        },
        "7ad5e22fd1ef4a2aa51811bfb76ee3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05776a29225e4b2f8e9473f3fa818961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b69c54d2d1b4214a2c527f7a023ac82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f631b9534c46529d87899b4b952564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d5eab5df4a43b583b87c1b61fd4b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5455da1593bd4b83affe37495bf8e4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eca6f23ef7416baeb3ca8a029b3ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc77861c3430458db3c3eee45cb2a057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41208a47e67a496ea62419c5dab015aa",
              "IPY_MODEL_a1850437033d4133adf6b82f6643c96a",
              "IPY_MODEL_b56875f6646e4e9bbdd3a13ba3f5e0a8"
            ],
            "layout": "IPY_MODEL_439e991e7dd249c3926556ab4ed95f9a"
          }
        },
        "41208a47e67a496ea62419c5dab015aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba38111356343afa8d78ae4e28db589",
            "placeholder": "​",
            "style": "IPY_MODEL_cd59dc6c04ae4fdaa636830ba84486c2",
            "value": "vocab.txt: 100%"
          }
        },
        "a1850437033d4133adf6b82f6643c96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23f4e70811a642a083a34c9bd5856166",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_467207822cbe47fea5ad3cd60492ab1c",
            "value": 231508
          }
        },
        "b56875f6646e4e9bbdd3a13ba3f5e0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c58151a1dae4255a4d65c7968306a14",
            "placeholder": "​",
            "style": "IPY_MODEL_adec21cfca704f748443e4fcb6064784",
            "value": " 232k/232k [00:00&lt;00:00, 4.93MB/s]"
          }
        },
        "439e991e7dd249c3926556ab4ed95f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba38111356343afa8d78ae4e28db589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd59dc6c04ae4fdaa636830ba84486c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f4e70811a642a083a34c9bd5856166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467207822cbe47fea5ad3cd60492ab1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c58151a1dae4255a4d65c7968306a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adec21cfca704f748443e4fcb6064784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d71a8e07dd8c447f825ab882f7b444ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68b3fa0a3a1e492488c662bf8cb9fdd9",
              "IPY_MODEL_3d0bb3b794374a55bfa5630507e5b934",
              "IPY_MODEL_eabbd87b2f3c4980bbaa3858c93dd0cd"
            ],
            "layout": "IPY_MODEL_ab4a42da00b64905809452c6d2d1b76b"
          }
        },
        "68b3fa0a3a1e492488c662bf8cb9fdd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7db88ee7ad49e3b16c16911b56e39d",
            "placeholder": "​",
            "style": "IPY_MODEL_859d1ba2797243a8a458cc68a39071fa",
            "value": "tokenizer.json: 100%"
          }
        },
        "3d0bb3b794374a55bfa5630507e5b934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1aebc2437174fdc95409b732cf45c3d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eb8e9e1d65249bfb889fc0f3cdf06a5",
            "value": 466062
          }
        },
        "eabbd87b2f3c4980bbaa3858c93dd0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c6d45876844fd6a9235cebc2bc1edd",
            "placeholder": "​",
            "style": "IPY_MODEL_185cc0468a984c17bbd2b57252b65309",
            "value": " 466k/466k [00:00&lt;00:00, 17.6MB/s]"
          }
        },
        "ab4a42da00b64905809452c6d2d1b76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7db88ee7ad49e3b16c16911b56e39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859d1ba2797243a8a458cc68a39071fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1aebc2437174fdc95409b732cf45c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eb8e9e1d65249bfb889fc0f3cdf06a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81c6d45876844fd6a9235cebc2bc1edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185cc0468a984c17bbd2b57252b65309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatima8024/NLP/blob/main/Sentiment_Analysis_using_Text2vec_with_RNN_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L2foO0ZDb_M",
        "outputId": "4a2fdaee-295b-4249-c39c-7481fb084f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorflow scikit-learn pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "RH308VkZF_vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "# Load the dataset\n",
        "df = pd.read_csv('COVID Fake News Data.csv')  # Replace with your file name\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IdLX1H8BDvKb",
        "outputId": "b518a10e-dab2-4df5-bbc2-25e9d6e12a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           headlines  outcome\n",
              "0  A post claims compulsory vacination violates t...        0\n",
              "1  A photo claims that this person is a doctor wh...        0\n",
              "2  Post about a video claims that it is a protest...        0\n",
              "3  All deaths by respiratory failure and pneumoni...        0\n",
              "4  The dean of the College of Biologists of Euska...        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52db2a22-b954-4c0a-9fed-e662393955e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A post claims compulsory vacination violates t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A photo claims that this person is a doctor wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Post about a video claims that it is a protest...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All deaths by respiratory failure and pneumoni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The dean of the College of Biologists of Euska...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52db2a22-b954-4c0a-9fed-e662393955e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52db2a22-b954-4c0a-9fed-e662393955e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52db2a22-b954-4c0a-9fed-e662393955e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ec9fd1d-cea0-4667-839b-16efc4fe8f24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ec9fd1d-cea0-4667-839b-16efc4fe8f24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ec9fd1d-cea0-4667-839b-16efc4fe8f24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10201,\n  \"fields\": [\n    {\n      \"column\": \"headlines\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8972,\n        \"samples\": [\n          \"Google waives Ad Serving fee for 5 months to support news partners during \\nCOVID-19 crisis\",\n          \"A claim that police in Thailand can issue fines to anyone who does not wear a face mask in public during the novel coronavirus pandemic has been shared repeatedly on Facebook, Twitter and Line Messenger.\",\n          \"Coffee cures the coronavirus.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "df['outcome'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qqIvE33JF2Tu",
        "outputId": "462cb4dc-58ed-44eb-f6d5-85c9c9073dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "outcome\n",
              "0    0.953534\n",
              "1    0.046466\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>outcome</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.953534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.046466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['headlines'], df['outcome'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['outcome'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "E8kKtQ3FHAxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "1744ce07a6e6402090ad7ddf41a45850",
            "b538cf1908534e09ba6453c29fb11270",
            "283b17e8e3e84ed0ab433fe7755d66bf",
            "e09a4bee6726402fbcfffc8bdb7a79b8",
            "ff207cd773f14e8787258ffe3049b9cb",
            "5be81f1968284ad2bf145d3d6619cd39",
            "eb2bb79a81c348adbd429546e7c3ed21",
            "13ee8c40b1434e26a4990fe275ae27d5",
            "ac081129468f471cba012d580d14c4ef",
            "97550feb8c454f4ab335fee532acdc6b",
            "fd9a2c08f45b452ea7d27703d96c5f19",
            "06c4863b25034c0db01112fe004c21d0",
            "9875dafa47794f19b3188555259bb907",
            "fb8f8459721a484f9879f1c1ab815f7b",
            "d0a18f97b6d341d081cd16a163d46a25",
            "ef6625ea313d43c89a2625c00c34ae9e",
            "64a5db8800ce4e21a2d78124b75e7004",
            "55294642c02241d69b039d823b243b23",
            "87e9c5b48c9c434bb45f9604440ab3d9",
            "16b4a8ba3e064484beacf36c263a069f",
            "6177dc39910b485e8774efc3ff6e0457",
            "3752018d46cf4bf5b21cd13333ef4a8b",
            "c5256c550acb4786931016a45f58d55b",
            "422ce2c139dc479c8337e8d1ede4dd0d",
            "6f98cd4b5e794771a1ab0aebf5d4ca74",
            "f90e0f100eeb4bbe896252e46c8f3c37",
            "7ad5e22fd1ef4a2aa51811bfb76ee3e2",
            "05776a29225e4b2f8e9473f3fa818961",
            "6b69c54d2d1b4214a2c527f7a023ac82",
            "77f631b9534c46529d87899b4b952564",
            "82d5eab5df4a43b583b87c1b61fd4b5d",
            "5455da1593bd4b83affe37495bf8e4d1",
            "51eca6f23ef7416baeb3ca8a029b3ad9",
            "bc77861c3430458db3c3eee45cb2a057",
            "41208a47e67a496ea62419c5dab015aa",
            "a1850437033d4133adf6b82f6643c96a",
            "b56875f6646e4e9bbdd3a13ba3f5e0a8",
            "439e991e7dd249c3926556ab4ed95f9a",
            "9ba38111356343afa8d78ae4e28db589",
            "cd59dc6c04ae4fdaa636830ba84486c2",
            "23f4e70811a642a083a34c9bd5856166",
            "467207822cbe47fea5ad3cd60492ab1c",
            "8c58151a1dae4255a4d65c7968306a14",
            "adec21cfca704f748443e4fcb6064784",
            "d71a8e07dd8c447f825ab882f7b444ae",
            "68b3fa0a3a1e492488c662bf8cb9fdd9",
            "3d0bb3b794374a55bfa5630507e5b934",
            "eabbd87b2f3c4980bbaa3858c93dd0cd",
            "ab4a42da00b64905809452c6d2d1b76b",
            "4f7db88ee7ad49e3b16c16911b56e39d",
            "859d1ba2797243a8a458cc68a39071fa",
            "b1aebc2437174fdc95409b732cf45c3d",
            "1eb8e9e1d65249bfb889fc0f3cdf06a5",
            "81c6d45876844fd6a9235cebc2bc1edd",
            "185cc0468a984c17bbd2b57252b65309"
          ]
        },
        "id": "G4yjGrMkHRC5",
        "outputId": "2ef35010-d284-4deb-b094-3ad67711e17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1744ce07a6e6402090ad7ddf41a45850"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06c4863b25034c0db01112fe004c21d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5256c550acb4786931016a45f58d55b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc77861c3430458db3c3eee45cb2a057"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d71a8e07dd8c447f825ab882f7b444ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "OAetR34NHbwx",
        "outputId": "9cb2e2b4-b011-44c6-edf1-b5c43fcf4e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = None,\n",
        "    padding='max_length',\n",
        "    #pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = None,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = None,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "hfNKoAcvHjC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# dataLoader for test set\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "0-erWLS7I1u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "3K8YWv6eKFZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "\n",
        "        self.bert = bert\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "        # dense layer 2 (Output layer)\n",
        "        self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "        #pass the inputs to the model\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Rm2hgV9UKPgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "rQKs7oC9KZY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "claUmqcmip-W",
        "outputId": "857a295c-ff4f-4595-9bfe-df1fcc834677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "import torch.optim as optim\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(),lr = 1e-5)\n",
        "\n",
        "#The compute_class_weight function from the sklearn.utils.class_weight module is used to compute the class weights with multiple parameters for the training labels.\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print('Class Weights:',class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-2R9pqbjGuR",
        "outputId": "36c88de6-0570-447f-e744-43d3bcf1e22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [ 0.52438308 10.75301205]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "gG-H18eWjAKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "qMLry60PmAqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # Record the starting time before evaluation\n",
        "    t0 = time.time()\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,} Elapsed: {}'.format(step, len(val_dataloader), elapsed))\n",
        "          #  print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "WTsql9TAmMKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#defining epochs\n",
        "epochs = 10\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxiiJ-i3ofea",
        "outputId": "f7497d51-d649-4c09-acc3-623ed14f6e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.575\n",
            "Validation Loss: 0.569\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.568\n",
            "Validation Loss: 0.554\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.546\n",
            "Validation Loss: 0.551\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.544\n",
            "Validation Loss: 0.534\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.530\n",
            "Validation Loss: 0.518\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.525\n",
            "Validation Loss: 0.512\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.521\n",
            "Validation Loss: 0.511\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.506\n",
            "Validation Loss: 0.501\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.508\n",
            "Validation Loss: 0.493\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.492\n",
            "Validation Loss: 0.475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best modelpath = 'saved_weights.pt'model.load_state_dict(torch.load(path))\n",
        "\n",
        "# Load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJZWbryZ2hfI",
        "outputId": "7dadb744-ae13-44be-bda5-125c2fddd054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data in batches\n",
        "batch_size = 32  # Adjust as needed\n",
        "preds_list = []\n",
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  for i in range(0, test_seq.shape[0], batch_size):\n",
        "        batch_seq = test_seq[i:i + batch_size].to(device)\n",
        "        batch_mask = test_mask[i:i + batch_size].to(device)\n",
        "        preds = model(batch_seq, batch_mask)\n",
        "        preds_list.extend(preds.detach().cpu().numpy())\n",
        "\n",
        "preds = np.array(preds_list)\n",
        "\n",
        "# get predictions for test data\n",
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "# Convert test_y to a NumPy array  <--- This is the added line\n",
        "test_y_np = test_y.cpu().numpy()  # Move to CPU and convert to NumPy\n",
        "\n",
        "print(classification_report(test_y, preds))\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predictions:\")\n",
        "for i, prediction in enumerate(preds):\n",
        "    print(f\"Sample {i}: {prediction}\")\n",
        "\n",
        "\n",
        "    #preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    #preds = preds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "# model's performance\n",
        "#preds = np.argmax(preds, axis = 1)\n",
        "#print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kODzoJFF3nbh",
        "outputId": "f9b1753b-d5d5-48fa-c6c0-c739a9cbe3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.95      1460\n",
            "           1       0.28      0.66      0.39        71\n",
            "\n",
            "    accuracy                           0.90      1531\n",
            "   macro avg       0.63      0.79      0.67      1531\n",
            "weighted avg       0.95      0.90      0.92      1531\n",
            "\n",
            "Predictions:\n",
            "Sample 0: 0\n",
            "Sample 1: 0\n",
            "Sample 2: 0\n",
            "Sample 3: 0\n",
            "Sample 4: 0\n",
            "Sample 5: 0\n",
            "Sample 6: 0\n",
            "Sample 7: 0\n",
            "Sample 8: 0\n",
            "Sample 9: 0\n",
            "Sample 10: 0\n",
            "Sample 11: 0\n",
            "Sample 12: 0\n",
            "Sample 13: 1\n",
            "Sample 14: 0\n",
            "Sample 15: 0\n",
            "Sample 16: 0\n",
            "Sample 17: 0\n",
            "Sample 18: 0\n",
            "Sample 19: 0\n",
            "Sample 20: 0\n",
            "Sample 21: 0\n",
            "Sample 22: 0\n",
            "Sample 23: 0\n",
            "Sample 24: 0\n",
            "Sample 25: 0\n",
            "Sample 26: 0\n",
            "Sample 27: 0\n",
            "Sample 28: 0\n",
            "Sample 29: 0\n",
            "Sample 30: 0\n",
            "Sample 31: 0\n",
            "Sample 32: 0\n",
            "Sample 33: 0\n",
            "Sample 34: 0\n",
            "Sample 35: 1\n",
            "Sample 36: 0\n",
            "Sample 37: 0\n",
            "Sample 38: 0\n",
            "Sample 39: 0\n",
            "Sample 40: 1\n",
            "Sample 41: 0\n",
            "Sample 42: 0\n",
            "Sample 43: 0\n",
            "Sample 44: 1\n",
            "Sample 45: 0\n",
            "Sample 46: 0\n",
            "Sample 47: 0\n",
            "Sample 48: 0\n",
            "Sample 49: 0\n",
            "Sample 50: 0\n",
            "Sample 51: 0\n",
            "Sample 52: 0\n",
            "Sample 53: 0\n",
            "Sample 54: 0\n",
            "Sample 55: 0\n",
            "Sample 56: 1\n",
            "Sample 57: 0\n",
            "Sample 58: 0\n",
            "Sample 59: 0\n",
            "Sample 60: 0\n",
            "Sample 61: 0\n",
            "Sample 62: 0\n",
            "Sample 63: 1\n",
            "Sample 64: 0\n",
            "Sample 65: 0\n",
            "Sample 66: 0\n",
            "Sample 67: 0\n",
            "Sample 68: 0\n",
            "Sample 69: 0\n",
            "Sample 70: 0\n",
            "Sample 71: 1\n",
            "Sample 72: 0\n",
            "Sample 73: 0\n",
            "Sample 74: 1\n",
            "Sample 75: 0\n",
            "Sample 76: 0\n",
            "Sample 77: 0\n",
            "Sample 78: 1\n",
            "Sample 79: 0\n",
            "Sample 80: 0\n",
            "Sample 81: 0\n",
            "Sample 82: 0\n",
            "Sample 83: 0\n",
            "Sample 84: 0\n",
            "Sample 85: 0\n",
            "Sample 86: 0\n",
            "Sample 87: 0\n",
            "Sample 88: 0\n",
            "Sample 89: 0\n",
            "Sample 90: 0\n",
            "Sample 91: 0\n",
            "Sample 92: 0\n",
            "Sample 93: 0\n",
            "Sample 94: 0\n",
            "Sample 95: 0\n",
            "Sample 96: 0\n",
            "Sample 97: 0\n",
            "Sample 98: 0\n",
            "Sample 99: 1\n",
            "Sample 100: 0\n",
            "Sample 101: 1\n",
            "Sample 102: 0\n",
            "Sample 103: 0\n",
            "Sample 104: 1\n",
            "Sample 105: 0\n",
            "Sample 106: 0\n",
            "Sample 107: 0\n",
            "Sample 108: 0\n",
            "Sample 109: 0\n",
            "Sample 110: 1\n",
            "Sample 111: 0\n",
            "Sample 112: 0\n",
            "Sample 113: 0\n",
            "Sample 114: 0\n",
            "Sample 115: 0\n",
            "Sample 116: 0\n",
            "Sample 117: 1\n",
            "Sample 118: 0\n",
            "Sample 119: 1\n",
            "Sample 120: 0\n",
            "Sample 121: 0\n",
            "Sample 122: 0\n",
            "Sample 123: 1\n",
            "Sample 124: 1\n",
            "Sample 125: 0\n",
            "Sample 126: 0\n",
            "Sample 127: 0\n",
            "Sample 128: 0\n",
            "Sample 129: 0\n",
            "Sample 130: 0\n",
            "Sample 131: 0\n",
            "Sample 132: 0\n",
            "Sample 133: 0\n",
            "Sample 134: 0\n",
            "Sample 135: 0\n",
            "Sample 136: 0\n",
            "Sample 137: 1\n",
            "Sample 138: 0\n",
            "Sample 139: 0\n",
            "Sample 140: 0\n",
            "Sample 141: 0\n",
            "Sample 142: 0\n",
            "Sample 143: 0\n",
            "Sample 144: 0\n",
            "Sample 145: 0\n",
            "Sample 146: 0\n",
            "Sample 147: 0\n",
            "Sample 148: 0\n",
            "Sample 149: 0\n",
            "Sample 150: 0\n",
            "Sample 151: 0\n",
            "Sample 152: 0\n",
            "Sample 153: 0\n",
            "Sample 154: 0\n",
            "Sample 155: 1\n",
            "Sample 156: 0\n",
            "Sample 157: 0\n",
            "Sample 158: 0\n",
            "Sample 159: 0\n",
            "Sample 160: 0\n",
            "Sample 161: 0\n",
            "Sample 162: 0\n",
            "Sample 163: 0\n",
            "Sample 164: 0\n",
            "Sample 165: 0\n",
            "Sample 166: 0\n",
            "Sample 167: 0\n",
            "Sample 168: 1\n",
            "Sample 169: 0\n",
            "Sample 170: 0\n",
            "Sample 171: 0\n",
            "Sample 172: 0\n",
            "Sample 173: 0\n",
            "Sample 174: 1\n",
            "Sample 175: 1\n",
            "Sample 176: 0\n",
            "Sample 177: 0\n",
            "Sample 178: 0\n",
            "Sample 179: 0\n",
            "Sample 180: 0\n",
            "Sample 181: 0\n",
            "Sample 182: 0\n",
            "Sample 183: 0\n",
            "Sample 184: 0\n",
            "Sample 185: 0\n",
            "Sample 186: 0\n",
            "Sample 187: 0\n",
            "Sample 188: 0\n",
            "Sample 189: 0\n",
            "Sample 190: 0\n",
            "Sample 191: 0\n",
            "Sample 192: 0\n",
            "Sample 193: 0\n",
            "Sample 194: 0\n",
            "Sample 195: 1\n",
            "Sample 196: 0\n",
            "Sample 197: 1\n",
            "Sample 198: 0\n",
            "Sample 199: 0\n",
            "Sample 200: 0\n",
            "Sample 201: 0\n",
            "Sample 202: 0\n",
            "Sample 203: 0\n",
            "Sample 204: 0\n",
            "Sample 205: 0\n",
            "Sample 206: 0\n",
            "Sample 207: 0\n",
            "Sample 208: 0\n",
            "Sample 209: 0\n",
            "Sample 210: 0\n",
            "Sample 211: 1\n",
            "Sample 212: 0\n",
            "Sample 213: 0\n",
            "Sample 214: 0\n",
            "Sample 215: 0\n",
            "Sample 216: 0\n",
            "Sample 217: 0\n",
            "Sample 218: 0\n",
            "Sample 219: 0\n",
            "Sample 220: 0\n",
            "Sample 221: 0\n",
            "Sample 222: 0\n",
            "Sample 223: 0\n",
            "Sample 224: 0\n",
            "Sample 225: 0\n",
            "Sample 226: 1\n",
            "Sample 227: 0\n",
            "Sample 228: 1\n",
            "Sample 229: 0\n",
            "Sample 230: 0\n",
            "Sample 231: 0\n",
            "Sample 232: 0\n",
            "Sample 233: 1\n",
            "Sample 234: 0\n",
            "Sample 235: 0\n",
            "Sample 236: 0\n",
            "Sample 237: 0\n",
            "Sample 238: 0\n",
            "Sample 239: 0\n",
            "Sample 240: 1\n",
            "Sample 241: 0\n",
            "Sample 242: 0\n",
            "Sample 243: 0\n",
            "Sample 244: 1\n",
            "Sample 245: 0\n",
            "Sample 246: 0\n",
            "Sample 247: 0\n",
            "Sample 248: 0\n",
            "Sample 249: 0\n",
            "Sample 250: 0\n",
            "Sample 251: 0\n",
            "Sample 252: 0\n",
            "Sample 253: 0\n",
            "Sample 254: 1\n",
            "Sample 255: 0\n",
            "Sample 256: 0\n",
            "Sample 257: 0\n",
            "Sample 258: 0\n",
            "Sample 259: 0\n",
            "Sample 260: 0\n",
            "Sample 261: 0\n",
            "Sample 262: 0\n",
            "Sample 263: 0\n",
            "Sample 264: 0\n",
            "Sample 265: 0\n",
            "Sample 266: 1\n",
            "Sample 267: 0\n",
            "Sample 268: 0\n",
            "Sample 269: 0\n",
            "Sample 270: 0\n",
            "Sample 271: 0\n",
            "Sample 272: 0\n",
            "Sample 273: 0\n",
            "Sample 274: 0\n",
            "Sample 275: 0\n",
            "Sample 276: 0\n",
            "Sample 277: 0\n",
            "Sample 278: 0\n",
            "Sample 279: 0\n",
            "Sample 280: 0\n",
            "Sample 281: 1\n",
            "Sample 282: 0\n",
            "Sample 283: 0\n",
            "Sample 284: 0\n",
            "Sample 285: 0\n",
            "Sample 286: 0\n",
            "Sample 287: 0\n",
            "Sample 288: 0\n",
            "Sample 289: 1\n",
            "Sample 290: 0\n",
            "Sample 291: 0\n",
            "Sample 292: 0\n",
            "Sample 293: 0\n",
            "Sample 294: 0\n",
            "Sample 295: 1\n",
            "Sample 296: 0\n",
            "Sample 297: 0\n",
            "Sample 298: 0\n",
            "Sample 299: 0\n",
            "Sample 300: 0\n",
            "Sample 301: 1\n",
            "Sample 302: 0\n",
            "Sample 303: 0\n",
            "Sample 304: 0\n",
            "Sample 305: 0\n",
            "Sample 306: 0\n",
            "Sample 307: 0\n",
            "Sample 308: 0\n",
            "Sample 309: 0\n",
            "Sample 310: 0\n",
            "Sample 311: 0\n",
            "Sample 312: 1\n",
            "Sample 313: 0\n",
            "Sample 314: 0\n",
            "Sample 315: 1\n",
            "Sample 316: 0\n",
            "Sample 317: 0\n",
            "Sample 318: 0\n",
            "Sample 319: 0\n",
            "Sample 320: 0\n",
            "Sample 321: 0\n",
            "Sample 322: 0\n",
            "Sample 323: 1\n",
            "Sample 324: 0\n",
            "Sample 325: 0\n",
            "Sample 326: 1\n",
            "Sample 327: 0\n",
            "Sample 328: 0\n",
            "Sample 329: 0\n",
            "Sample 330: 0\n",
            "Sample 331: 0\n",
            "Sample 332: 0\n",
            "Sample 333: 0\n",
            "Sample 334: 1\n",
            "Sample 335: 0\n",
            "Sample 336: 0\n",
            "Sample 337: 0\n",
            "Sample 338: 0\n",
            "Sample 339: 0\n",
            "Sample 340: 0\n",
            "Sample 341: 1\n",
            "Sample 342: 0\n",
            "Sample 343: 0\n",
            "Sample 344: 0\n",
            "Sample 345: 0\n",
            "Sample 346: 0\n",
            "Sample 347: 0\n",
            "Sample 348: 0\n",
            "Sample 349: 0\n",
            "Sample 350: 0\n",
            "Sample 351: 0\n",
            "Sample 352: 0\n",
            "Sample 353: 0\n",
            "Sample 354: 0\n",
            "Sample 355: 0\n",
            "Sample 356: 0\n",
            "Sample 357: 0\n",
            "Sample 358: 0\n",
            "Sample 359: 0\n",
            "Sample 360: 0\n",
            "Sample 361: 0\n",
            "Sample 362: 0\n",
            "Sample 363: 0\n",
            "Sample 364: 0\n",
            "Sample 365: 0\n",
            "Sample 366: 1\n",
            "Sample 367: 0\n",
            "Sample 368: 1\n",
            "Sample 369: 0\n",
            "Sample 370: 0\n",
            "Sample 371: 1\n",
            "Sample 372: 0\n",
            "Sample 373: 0\n",
            "Sample 374: 0\n",
            "Sample 375: 0\n",
            "Sample 376: 1\n",
            "Sample 377: 0\n",
            "Sample 378: 0\n",
            "Sample 379: 1\n",
            "Sample 380: 0\n",
            "Sample 381: 0\n",
            "Sample 382: 0\n",
            "Sample 383: 0\n",
            "Sample 384: 0\n",
            "Sample 385: 0\n",
            "Sample 386: 0\n",
            "Sample 387: 0\n",
            "Sample 388: 0\n",
            "Sample 389: 0\n",
            "Sample 390: 1\n",
            "Sample 391: 0\n",
            "Sample 392: 0\n",
            "Sample 393: 1\n",
            "Sample 394: 0\n",
            "Sample 395: 1\n",
            "Sample 396: 0\n",
            "Sample 397: 0\n",
            "Sample 398: 0\n",
            "Sample 399: 0\n",
            "Sample 400: 0\n",
            "Sample 401: 0\n",
            "Sample 402: 0\n",
            "Sample 403: 0\n",
            "Sample 404: 0\n",
            "Sample 405: 0\n",
            "Sample 406: 0\n",
            "Sample 407: 0\n",
            "Sample 408: 1\n",
            "Sample 409: 0\n",
            "Sample 410: 0\n",
            "Sample 411: 0\n",
            "Sample 412: 0\n",
            "Sample 413: 0\n",
            "Sample 414: 0\n",
            "Sample 415: 0\n",
            "Sample 416: 0\n",
            "Sample 417: 0\n",
            "Sample 418: 0\n",
            "Sample 419: 0\n",
            "Sample 420: 1\n",
            "Sample 421: 0\n",
            "Sample 422: 0\n",
            "Sample 423: 0\n",
            "Sample 424: 0\n",
            "Sample 425: 1\n",
            "Sample 426: 0\n",
            "Sample 427: 0\n",
            "Sample 428: 0\n",
            "Sample 429: 0\n",
            "Sample 430: 0\n",
            "Sample 431: 0\n",
            "Sample 432: 0\n",
            "Sample 433: 0\n",
            "Sample 434: 0\n",
            "Sample 435: 0\n",
            "Sample 436: 1\n",
            "Sample 437: 0\n",
            "Sample 438: 0\n",
            "Sample 439: 0\n",
            "Sample 440: 0\n",
            "Sample 441: 0\n",
            "Sample 442: 0\n",
            "Sample 443: 1\n",
            "Sample 444: 0\n",
            "Sample 445: 0\n",
            "Sample 446: 0\n",
            "Sample 447: 0\n",
            "Sample 448: 0\n",
            "Sample 449: 0\n",
            "Sample 450: 0\n",
            "Sample 451: 0\n",
            "Sample 452: 0\n",
            "Sample 453: 0\n",
            "Sample 454: 0\n",
            "Sample 455: 0\n",
            "Sample 456: 0\n",
            "Sample 457: 0\n",
            "Sample 458: 0\n",
            "Sample 459: 0\n",
            "Sample 460: 0\n",
            "Sample 461: 0\n",
            "Sample 462: 0\n",
            "Sample 463: 0\n",
            "Sample 464: 0\n",
            "Sample 465: 0\n",
            "Sample 466: 0\n",
            "Sample 467: 1\n",
            "Sample 468: 0\n",
            "Sample 469: 0\n",
            "Sample 470: 0\n",
            "Sample 471: 1\n",
            "Sample 472: 0\n",
            "Sample 473: 0\n",
            "Sample 474: 0\n",
            "Sample 475: 0\n",
            "Sample 476: 1\n",
            "Sample 477: 0\n",
            "Sample 478: 0\n",
            "Sample 479: 0\n",
            "Sample 480: 0\n",
            "Sample 481: 0\n",
            "Sample 482: 0\n",
            "Sample 483: 0\n",
            "Sample 484: 0\n",
            "Sample 485: 0\n",
            "Sample 486: 0\n",
            "Sample 487: 0\n",
            "Sample 488: 0\n",
            "Sample 489: 0\n",
            "Sample 490: 0\n",
            "Sample 491: 0\n",
            "Sample 492: 0\n",
            "Sample 493: 0\n",
            "Sample 494: 0\n",
            "Sample 495: 0\n",
            "Sample 496: 0\n",
            "Sample 497: 0\n",
            "Sample 498: 0\n",
            "Sample 499: 0\n",
            "Sample 500: 0\n",
            "Sample 501: 0\n",
            "Sample 502: 0\n",
            "Sample 503: 0\n",
            "Sample 504: 0\n",
            "Sample 505: 0\n",
            "Sample 506: 0\n",
            "Sample 507: 1\n",
            "Sample 508: 0\n",
            "Sample 509: 0\n",
            "Sample 510: 1\n",
            "Sample 511: 0\n",
            "Sample 512: 0\n",
            "Sample 513: 0\n",
            "Sample 514: 0\n",
            "Sample 515: 0\n",
            "Sample 516: 0\n",
            "Sample 517: 1\n",
            "Sample 518: 0\n",
            "Sample 519: 0\n",
            "Sample 520: 0\n",
            "Sample 521: 0\n",
            "Sample 522: 0\n",
            "Sample 523: 0\n",
            "Sample 524: 0\n",
            "Sample 525: 0\n",
            "Sample 526: 0\n",
            "Sample 527: 0\n",
            "Sample 528: 1\n",
            "Sample 529: 0\n",
            "Sample 530: 0\n",
            "Sample 531: 0\n",
            "Sample 532: 0\n",
            "Sample 533: 0\n",
            "Sample 534: 0\n",
            "Sample 535: 0\n",
            "Sample 536: 0\n",
            "Sample 537: 0\n",
            "Sample 538: 1\n",
            "Sample 539: 0\n",
            "Sample 540: 1\n",
            "Sample 541: 0\n",
            "Sample 542: 0\n",
            "Sample 543: 0\n",
            "Sample 544: 1\n",
            "Sample 545: 0\n",
            "Sample 546: 1\n",
            "Sample 547: 0\n",
            "Sample 548: 0\n",
            "Sample 549: 0\n",
            "Sample 550: 0\n",
            "Sample 551: 1\n",
            "Sample 552: 0\n",
            "Sample 553: 0\n",
            "Sample 554: 0\n",
            "Sample 555: 0\n",
            "Sample 556: 0\n",
            "Sample 557: 0\n",
            "Sample 558: 0\n",
            "Sample 559: 0\n",
            "Sample 560: 1\n",
            "Sample 561: 0\n",
            "Sample 562: 0\n",
            "Sample 563: 0\n",
            "Sample 564: 0\n",
            "Sample 565: 0\n",
            "Sample 566: 0\n",
            "Sample 567: 0\n",
            "Sample 568: 0\n",
            "Sample 569: 0\n",
            "Sample 570: 0\n",
            "Sample 571: 0\n",
            "Sample 572: 0\n",
            "Sample 573: 0\n",
            "Sample 574: 0\n",
            "Sample 575: 0\n",
            "Sample 576: 0\n",
            "Sample 577: 1\n",
            "Sample 578: 0\n",
            "Sample 579: 0\n",
            "Sample 580: 0\n",
            "Sample 581: 0\n",
            "Sample 582: 0\n",
            "Sample 583: 0\n",
            "Sample 584: 0\n",
            "Sample 585: 0\n",
            "Sample 586: 0\n",
            "Sample 587: 0\n",
            "Sample 588: 0\n",
            "Sample 589: 0\n",
            "Sample 590: 0\n",
            "Sample 591: 1\n",
            "Sample 592: 0\n",
            "Sample 593: 0\n",
            "Sample 594: 1\n",
            "Sample 595: 0\n",
            "Sample 596: 0\n",
            "Sample 597: 0\n",
            "Sample 598: 0\n",
            "Sample 599: 1\n",
            "Sample 600: 0\n",
            "Sample 601: 0\n",
            "Sample 602: 0\n",
            "Sample 603: 0\n",
            "Sample 604: 0\n",
            "Sample 605: 0\n",
            "Sample 606: 0\n",
            "Sample 607: 0\n",
            "Sample 608: 0\n",
            "Sample 609: 0\n",
            "Sample 610: 0\n",
            "Sample 611: 0\n",
            "Sample 612: 0\n",
            "Sample 613: 0\n",
            "Sample 614: 0\n",
            "Sample 615: 0\n",
            "Sample 616: 1\n",
            "Sample 617: 0\n",
            "Sample 618: 0\n",
            "Sample 619: 0\n",
            "Sample 620: 0\n",
            "Sample 621: 0\n",
            "Sample 622: 0\n",
            "Sample 623: 0\n",
            "Sample 624: 0\n",
            "Sample 625: 1\n",
            "Sample 626: 0\n",
            "Sample 627: 0\n",
            "Sample 628: 0\n",
            "Sample 629: 0\n",
            "Sample 630: 0\n",
            "Sample 631: 0\n",
            "Sample 632: 0\n",
            "Sample 633: 0\n",
            "Sample 634: 0\n",
            "Sample 635: 0\n",
            "Sample 636: 0\n",
            "Sample 637: 0\n",
            "Sample 638: 0\n",
            "Sample 639: 0\n",
            "Sample 640: 0\n",
            "Sample 641: 0\n",
            "Sample 642: 0\n",
            "Sample 643: 0\n",
            "Sample 644: 0\n",
            "Sample 645: 1\n",
            "Sample 646: 0\n",
            "Sample 647: 0\n",
            "Sample 648: 0\n",
            "Sample 649: 0\n",
            "Sample 650: 0\n",
            "Sample 651: 0\n",
            "Sample 652: 0\n",
            "Sample 653: 1\n",
            "Sample 654: 0\n",
            "Sample 655: 0\n",
            "Sample 656: 0\n",
            "Sample 657: 0\n",
            "Sample 658: 0\n",
            "Sample 659: 1\n",
            "Sample 660: 0\n",
            "Sample 661: 0\n",
            "Sample 662: 0\n",
            "Sample 663: 0\n",
            "Sample 664: 0\n",
            "Sample 665: 0\n",
            "Sample 666: 0\n",
            "Sample 667: 0\n",
            "Sample 668: 0\n",
            "Sample 669: 0\n",
            "Sample 670: 1\n",
            "Sample 671: 0\n",
            "Sample 672: 0\n",
            "Sample 673: 0\n",
            "Sample 674: 0\n",
            "Sample 675: 0\n",
            "Sample 676: 0\n",
            "Sample 677: 0\n",
            "Sample 678: 0\n",
            "Sample 679: 0\n",
            "Sample 680: 0\n",
            "Sample 681: 1\n",
            "Sample 682: 0\n",
            "Sample 683: 0\n",
            "Sample 684: 0\n",
            "Sample 685: 0\n",
            "Sample 686: 0\n",
            "Sample 687: 0\n",
            "Sample 688: 0\n",
            "Sample 689: 0\n",
            "Sample 690: 0\n",
            "Sample 691: 1\n",
            "Sample 692: 0\n",
            "Sample 693: 0\n",
            "Sample 694: 0\n",
            "Sample 695: 1\n",
            "Sample 696: 0\n",
            "Sample 697: 0\n",
            "Sample 698: 0\n",
            "Sample 699: 0\n",
            "Sample 700: 0\n",
            "Sample 701: 0\n",
            "Sample 702: 0\n",
            "Sample 703: 0\n",
            "Sample 704: 0\n",
            "Sample 705: 0\n",
            "Sample 706: 0\n",
            "Sample 707: 0\n",
            "Sample 708: 0\n",
            "Sample 709: 0\n",
            "Sample 710: 0\n",
            "Sample 711: 0\n",
            "Sample 712: 1\n",
            "Sample 713: 1\n",
            "Sample 714: 0\n",
            "Sample 715: 0\n",
            "Sample 716: 0\n",
            "Sample 717: 0\n",
            "Sample 718: 0\n",
            "Sample 719: 0\n",
            "Sample 720: 1\n",
            "Sample 721: 0\n",
            "Sample 722: 0\n",
            "Sample 723: 0\n",
            "Sample 724: 0\n",
            "Sample 725: 0\n",
            "Sample 726: 0\n",
            "Sample 727: 0\n",
            "Sample 728: 0\n",
            "Sample 729: 0\n",
            "Sample 730: 0\n",
            "Sample 731: 0\n",
            "Sample 732: 0\n",
            "Sample 733: 1\n",
            "Sample 734: 0\n",
            "Sample 735: 0\n",
            "Sample 736: 0\n",
            "Sample 737: 0\n",
            "Sample 738: 0\n",
            "Sample 739: 0\n",
            "Sample 740: 0\n",
            "Sample 741: 0\n",
            "Sample 742: 0\n",
            "Sample 743: 0\n",
            "Sample 744: 0\n",
            "Sample 745: 0\n",
            "Sample 746: 0\n",
            "Sample 747: 0\n",
            "Sample 748: 0\n",
            "Sample 749: 0\n",
            "Sample 750: 0\n",
            "Sample 751: 1\n",
            "Sample 752: 0\n",
            "Sample 753: 0\n",
            "Sample 754: 0\n",
            "Sample 755: 0\n",
            "Sample 756: 0\n",
            "Sample 757: 0\n",
            "Sample 758: 0\n",
            "Sample 759: 0\n",
            "Sample 760: 0\n",
            "Sample 761: 0\n",
            "Sample 762: 0\n",
            "Sample 763: 0\n",
            "Sample 764: 0\n",
            "Sample 765: 0\n",
            "Sample 766: 0\n",
            "Sample 767: 0\n",
            "Sample 768: 0\n",
            "Sample 769: 0\n",
            "Sample 770: 0\n",
            "Sample 771: 0\n",
            "Sample 772: 1\n",
            "Sample 773: 0\n",
            "Sample 774: 0\n",
            "Sample 775: 0\n",
            "Sample 776: 1\n",
            "Sample 777: 1\n",
            "Sample 778: 0\n",
            "Sample 779: 0\n",
            "Sample 780: 0\n",
            "Sample 781: 0\n",
            "Sample 782: 0\n",
            "Sample 783: 0\n",
            "Sample 784: 0\n",
            "Sample 785: 0\n",
            "Sample 786: 0\n",
            "Sample 787: 0\n",
            "Sample 788: 0\n",
            "Sample 789: 1\n",
            "Sample 790: 0\n",
            "Sample 791: 0\n",
            "Sample 792: 0\n",
            "Sample 793: 0\n",
            "Sample 794: 0\n",
            "Sample 795: 0\n",
            "Sample 796: 0\n",
            "Sample 797: 0\n",
            "Sample 798: 0\n",
            "Sample 799: 0\n",
            "Sample 800: 0\n",
            "Sample 801: 0\n",
            "Sample 802: 0\n",
            "Sample 803: 0\n",
            "Sample 804: 0\n",
            "Sample 805: 0\n",
            "Sample 806: 0\n",
            "Sample 807: 0\n",
            "Sample 808: 0\n",
            "Sample 809: 0\n",
            "Sample 810: 0\n",
            "Sample 811: 0\n",
            "Sample 812: 0\n",
            "Sample 813: 0\n",
            "Sample 814: 1\n",
            "Sample 815: 0\n",
            "Sample 816: 0\n",
            "Sample 817: 0\n",
            "Sample 818: 0\n",
            "Sample 819: 0\n",
            "Sample 820: 1\n",
            "Sample 821: 0\n",
            "Sample 822: 1\n",
            "Sample 823: 1\n",
            "Sample 824: 0\n",
            "Sample 825: 0\n",
            "Sample 826: 1\n",
            "Sample 827: 0\n",
            "Sample 828: 0\n",
            "Sample 829: 0\n",
            "Sample 830: 0\n",
            "Sample 831: 0\n",
            "Sample 832: 0\n",
            "Sample 833: 0\n",
            "Sample 834: 0\n",
            "Sample 835: 0\n",
            "Sample 836: 0\n",
            "Sample 837: 0\n",
            "Sample 838: 0\n",
            "Sample 839: 0\n",
            "Sample 840: 0\n",
            "Sample 841: 0\n",
            "Sample 842: 0\n",
            "Sample 843: 0\n",
            "Sample 844: 0\n",
            "Sample 845: 0\n",
            "Sample 846: 0\n",
            "Sample 847: 0\n",
            "Sample 848: 0\n",
            "Sample 849: 0\n",
            "Sample 850: 0\n",
            "Sample 851: 0\n",
            "Sample 852: 0\n",
            "Sample 853: 0\n",
            "Sample 854: 0\n",
            "Sample 855: 0\n",
            "Sample 856: 0\n",
            "Sample 857: 0\n",
            "Sample 858: 0\n",
            "Sample 859: 0\n",
            "Sample 860: 0\n",
            "Sample 861: 0\n",
            "Sample 862: 0\n",
            "Sample 863: 0\n",
            "Sample 864: 0\n",
            "Sample 865: 0\n",
            "Sample 866: 0\n",
            "Sample 867: 0\n",
            "Sample 868: 0\n",
            "Sample 869: 0\n",
            "Sample 870: 0\n",
            "Sample 871: 0\n",
            "Sample 872: 0\n",
            "Sample 873: 0\n",
            "Sample 874: 0\n",
            "Sample 875: 0\n",
            "Sample 876: 0\n",
            "Sample 877: 0\n",
            "Sample 878: 0\n",
            "Sample 879: 0\n",
            "Sample 880: 0\n",
            "Sample 881: 0\n",
            "Sample 882: 0\n",
            "Sample 883: 1\n",
            "Sample 884: 0\n",
            "Sample 885: 0\n",
            "Sample 886: 0\n",
            "Sample 887: 0\n",
            "Sample 888: 0\n",
            "Sample 889: 0\n",
            "Sample 890: 0\n",
            "Sample 891: 0\n",
            "Sample 892: 0\n",
            "Sample 893: 0\n",
            "Sample 894: 0\n",
            "Sample 895: 0\n",
            "Sample 896: 0\n",
            "Sample 897: 0\n",
            "Sample 898: 0\n",
            "Sample 899: 0\n",
            "Sample 900: 0\n",
            "Sample 901: 0\n",
            "Sample 902: 0\n",
            "Sample 903: 1\n",
            "Sample 904: 0\n",
            "Sample 905: 1\n",
            "Sample 906: 1\n",
            "Sample 907: 0\n",
            "Sample 908: 1\n",
            "Sample 909: 0\n",
            "Sample 910: 0\n",
            "Sample 911: 0\n",
            "Sample 912: 0\n",
            "Sample 913: 0\n",
            "Sample 914: 0\n",
            "Sample 915: 0\n",
            "Sample 916: 0\n",
            "Sample 917: 0\n",
            "Sample 918: 0\n",
            "Sample 919: 0\n",
            "Sample 920: 0\n",
            "Sample 921: 1\n",
            "Sample 922: 0\n",
            "Sample 923: 0\n",
            "Sample 924: 0\n",
            "Sample 925: 1\n",
            "Sample 926: 0\n",
            "Sample 927: 0\n",
            "Sample 928: 0\n",
            "Sample 929: 0\n",
            "Sample 930: 0\n",
            "Sample 931: 1\n",
            "Sample 932: 0\n",
            "Sample 933: 1\n",
            "Sample 934: 0\n",
            "Sample 935: 0\n",
            "Sample 936: 1\n",
            "Sample 937: 0\n",
            "Sample 938: 0\n",
            "Sample 939: 1\n",
            "Sample 940: 0\n",
            "Sample 941: 0\n",
            "Sample 942: 0\n",
            "Sample 943: 1\n",
            "Sample 944: 0\n",
            "Sample 945: 0\n",
            "Sample 946: 0\n",
            "Sample 947: 0\n",
            "Sample 948: 0\n",
            "Sample 949: 1\n",
            "Sample 950: 0\n",
            "Sample 951: 0\n",
            "Sample 952: 0\n",
            "Sample 953: 0\n",
            "Sample 954: 0\n",
            "Sample 955: 0\n",
            "Sample 956: 0\n",
            "Sample 957: 0\n",
            "Sample 958: 1\n",
            "Sample 959: 0\n",
            "Sample 960: 0\n",
            "Sample 961: 0\n",
            "Sample 962: 0\n",
            "Sample 963: 0\n",
            "Sample 964: 0\n",
            "Sample 965: 0\n",
            "Sample 966: 0\n",
            "Sample 967: 0\n",
            "Sample 968: 0\n",
            "Sample 969: 0\n",
            "Sample 970: 0\n",
            "Sample 971: 0\n",
            "Sample 972: 0\n",
            "Sample 973: 0\n",
            "Sample 974: 0\n",
            "Sample 975: 0\n",
            "Sample 976: 0\n",
            "Sample 977: 1\n",
            "Sample 978: 0\n",
            "Sample 979: 0\n",
            "Sample 980: 0\n",
            "Sample 981: 0\n",
            "Sample 982: 0\n",
            "Sample 983: 0\n",
            "Sample 984: 0\n",
            "Sample 985: 1\n",
            "Sample 986: 1\n",
            "Sample 987: 0\n",
            "Sample 988: 1\n",
            "Sample 989: 0\n",
            "Sample 990: 0\n",
            "Sample 991: 0\n",
            "Sample 992: 0\n",
            "Sample 993: 0\n",
            "Sample 994: 0\n",
            "Sample 995: 0\n",
            "Sample 996: 0\n",
            "Sample 997: 0\n",
            "Sample 998: 0\n",
            "Sample 999: 1\n",
            "Sample 1000: 0\n",
            "Sample 1001: 0\n",
            "Sample 1002: 0\n",
            "Sample 1003: 0\n",
            "Sample 1004: 0\n",
            "Sample 1005: 0\n",
            "Sample 1006: 0\n",
            "Sample 1007: 0\n",
            "Sample 1008: 0\n",
            "Sample 1009: 0\n",
            "Sample 1010: 0\n",
            "Sample 1011: 0\n",
            "Sample 1012: 0\n",
            "Sample 1013: 0\n",
            "Sample 1014: 0\n",
            "Sample 1015: 0\n",
            "Sample 1016: 1\n",
            "Sample 1017: 0\n",
            "Sample 1018: 0\n",
            "Sample 1019: 0\n",
            "Sample 1020: 0\n",
            "Sample 1021: 0\n",
            "Sample 1022: 1\n",
            "Sample 1023: 0\n",
            "Sample 1024: 1\n",
            "Sample 1025: 0\n",
            "Sample 1026: 0\n",
            "Sample 1027: 0\n",
            "Sample 1028: 0\n",
            "Sample 1029: 0\n",
            "Sample 1030: 0\n",
            "Sample 1031: 0\n",
            "Sample 1032: 0\n",
            "Sample 1033: 0\n",
            "Sample 1034: 0\n",
            "Sample 1035: 1\n",
            "Sample 1036: 0\n",
            "Sample 1037: 0\n",
            "Sample 1038: 0\n",
            "Sample 1039: 0\n",
            "Sample 1040: 0\n",
            "Sample 1041: 1\n",
            "Sample 1042: 1\n",
            "Sample 1043: 0\n",
            "Sample 1044: 0\n",
            "Sample 1045: 0\n",
            "Sample 1046: 0\n",
            "Sample 1047: 0\n",
            "Sample 1048: 0\n",
            "Sample 1049: 0\n",
            "Sample 1050: 0\n",
            "Sample 1051: 0\n",
            "Sample 1052: 0\n",
            "Sample 1053: 0\n",
            "Sample 1054: 0\n",
            "Sample 1055: 0\n",
            "Sample 1056: 0\n",
            "Sample 1057: 0\n",
            "Sample 1058: 1\n",
            "Sample 1059: 0\n",
            "Sample 1060: 0\n",
            "Sample 1061: 0\n",
            "Sample 1062: 0\n",
            "Sample 1063: 0\n",
            "Sample 1064: 0\n",
            "Sample 1065: 0\n",
            "Sample 1066: 0\n",
            "Sample 1067: 0\n",
            "Sample 1068: 0\n",
            "Sample 1069: 0\n",
            "Sample 1070: 0\n",
            "Sample 1071: 1\n",
            "Sample 1072: 0\n",
            "Sample 1073: 0\n",
            "Sample 1074: 0\n",
            "Sample 1075: 1\n",
            "Sample 1076: 0\n",
            "Sample 1077: 0\n",
            "Sample 1078: 0\n",
            "Sample 1079: 0\n",
            "Sample 1080: 0\n",
            "Sample 1081: 0\n",
            "Sample 1082: 0\n",
            "Sample 1083: 0\n",
            "Sample 1084: 0\n",
            "Sample 1085: 0\n",
            "Sample 1086: 0\n",
            "Sample 1087: 1\n",
            "Sample 1088: 0\n",
            "Sample 1089: 0\n",
            "Sample 1090: 0\n",
            "Sample 1091: 0\n",
            "Sample 1092: 0\n",
            "Sample 1093: 0\n",
            "Sample 1094: 1\n",
            "Sample 1095: 0\n",
            "Sample 1096: 0\n",
            "Sample 1097: 0\n",
            "Sample 1098: 0\n",
            "Sample 1099: 1\n",
            "Sample 1100: 0\n",
            "Sample 1101: 0\n",
            "Sample 1102: 0\n",
            "Sample 1103: 1\n",
            "Sample 1104: 0\n",
            "Sample 1105: 0\n",
            "Sample 1106: 0\n",
            "Sample 1107: 0\n",
            "Sample 1108: 0\n",
            "Sample 1109: 0\n",
            "Sample 1110: 0\n",
            "Sample 1111: 1\n",
            "Sample 1112: 0\n",
            "Sample 1113: 0\n",
            "Sample 1114: 0\n",
            "Sample 1115: 0\n",
            "Sample 1116: 1\n",
            "Sample 1117: 0\n",
            "Sample 1118: 0\n",
            "Sample 1119: 0\n",
            "Sample 1120: 0\n",
            "Sample 1121: 0\n",
            "Sample 1122: 0\n",
            "Sample 1123: 0\n",
            "Sample 1124: 1\n",
            "Sample 1125: 0\n",
            "Sample 1126: 0\n",
            "Sample 1127: 1\n",
            "Sample 1128: 0\n",
            "Sample 1129: 0\n",
            "Sample 1130: 0\n",
            "Sample 1131: 0\n",
            "Sample 1132: 0\n",
            "Sample 1133: 0\n",
            "Sample 1134: 1\n",
            "Sample 1135: 0\n",
            "Sample 1136: 1\n",
            "Sample 1137: 0\n",
            "Sample 1138: 0\n",
            "Sample 1139: 0\n",
            "Sample 1140: 0\n",
            "Sample 1141: 0\n",
            "Sample 1142: 0\n",
            "Sample 1143: 0\n",
            "Sample 1144: 0\n",
            "Sample 1145: 0\n",
            "Sample 1146: 0\n",
            "Sample 1147: 1\n",
            "Sample 1148: 0\n",
            "Sample 1149: 0\n",
            "Sample 1150: 0\n",
            "Sample 1151: 0\n",
            "Sample 1152: 0\n",
            "Sample 1153: 0\n",
            "Sample 1154: 0\n",
            "Sample 1155: 1\n",
            "Sample 1156: 0\n",
            "Sample 1157: 1\n",
            "Sample 1158: 0\n",
            "Sample 1159: 0\n",
            "Sample 1160: 0\n",
            "Sample 1161: 0\n",
            "Sample 1162: 0\n",
            "Sample 1163: 0\n",
            "Sample 1164: 0\n",
            "Sample 1165: 0\n",
            "Sample 1166: 0\n",
            "Sample 1167: 1\n",
            "Sample 1168: 0\n",
            "Sample 1169: 1\n",
            "Sample 1170: 0\n",
            "Sample 1171: 0\n",
            "Sample 1172: 0\n",
            "Sample 1173: 0\n",
            "Sample 1174: 1\n",
            "Sample 1175: 0\n",
            "Sample 1176: 0\n",
            "Sample 1177: 0\n",
            "Sample 1178: 1\n",
            "Sample 1179: 0\n",
            "Sample 1180: 0\n",
            "Sample 1181: 0\n",
            "Sample 1182: 0\n",
            "Sample 1183: 0\n",
            "Sample 1184: 0\n",
            "Sample 1185: 0\n",
            "Sample 1186: 0\n",
            "Sample 1187: 0\n",
            "Sample 1188: 0\n",
            "Sample 1189: 0\n",
            "Sample 1190: 1\n",
            "Sample 1191: 0\n",
            "Sample 1192: 0\n",
            "Sample 1193: 0\n",
            "Sample 1194: 0\n",
            "Sample 1195: 0\n",
            "Sample 1196: 0\n",
            "Sample 1197: 0\n",
            "Sample 1198: 0\n",
            "Sample 1199: 0\n",
            "Sample 1200: 0\n",
            "Sample 1201: 1\n",
            "Sample 1202: 0\n",
            "Sample 1203: 0\n",
            "Sample 1204: 1\n",
            "Sample 1205: 0\n",
            "Sample 1206: 0\n",
            "Sample 1207: 1\n",
            "Sample 1208: 0\n",
            "Sample 1209: 0\n",
            "Sample 1210: 0\n",
            "Sample 1211: 0\n",
            "Sample 1212: 0\n",
            "Sample 1213: 0\n",
            "Sample 1214: 0\n",
            "Sample 1215: 1\n",
            "Sample 1216: 0\n",
            "Sample 1217: 0\n",
            "Sample 1218: 0\n",
            "Sample 1219: 0\n",
            "Sample 1220: 0\n",
            "Sample 1221: 0\n",
            "Sample 1222: 0\n",
            "Sample 1223: 0\n",
            "Sample 1224: 0\n",
            "Sample 1225: 0\n",
            "Sample 1226: 1\n",
            "Sample 1227: 0\n",
            "Sample 1228: 1\n",
            "Sample 1229: 0\n",
            "Sample 1230: 0\n",
            "Sample 1231: 0\n",
            "Sample 1232: 0\n",
            "Sample 1233: 0\n",
            "Sample 1234: 0\n",
            "Sample 1235: 0\n",
            "Sample 1236: 0\n",
            "Sample 1237: 0\n",
            "Sample 1238: 0\n",
            "Sample 1239: 1\n",
            "Sample 1240: 0\n",
            "Sample 1241: 0\n",
            "Sample 1242: 0\n",
            "Sample 1243: 0\n",
            "Sample 1244: 0\n",
            "Sample 1245: 0\n",
            "Sample 1246: 0\n",
            "Sample 1247: 1\n",
            "Sample 1248: 0\n",
            "Sample 1249: 0\n",
            "Sample 1250: 0\n",
            "Sample 1251: 0\n",
            "Sample 1252: 0\n",
            "Sample 1253: 0\n",
            "Sample 1254: 0\n",
            "Sample 1255: 0\n",
            "Sample 1256: 0\n",
            "Sample 1257: 0\n",
            "Sample 1258: 0\n",
            "Sample 1259: 0\n",
            "Sample 1260: 0\n",
            "Sample 1261: 0\n",
            "Sample 1262: 0\n",
            "Sample 1263: 0\n",
            "Sample 1264: 0\n",
            "Sample 1265: 0\n",
            "Sample 1266: 0\n",
            "Sample 1267: 0\n",
            "Sample 1268: 1\n",
            "Sample 1269: 0\n",
            "Sample 1270: 0\n",
            "Sample 1271: 0\n",
            "Sample 1272: 0\n",
            "Sample 1273: 0\n",
            "Sample 1274: 0\n",
            "Sample 1275: 0\n",
            "Sample 1276: 0\n",
            "Sample 1277: 0\n",
            "Sample 1278: 0\n",
            "Sample 1279: 0\n",
            "Sample 1280: 0\n",
            "Sample 1281: 0\n",
            "Sample 1282: 0\n",
            "Sample 1283: 0\n",
            "Sample 1284: 0\n",
            "Sample 1285: 0\n",
            "Sample 1286: 0\n",
            "Sample 1287: 0\n",
            "Sample 1288: 0\n",
            "Sample 1289: 0\n",
            "Sample 1290: 1\n",
            "Sample 1291: 0\n",
            "Sample 1292: 0\n",
            "Sample 1293: 0\n",
            "Sample 1294: 0\n",
            "Sample 1295: 0\n",
            "Sample 1296: 0\n",
            "Sample 1297: 0\n",
            "Sample 1298: 0\n",
            "Sample 1299: 0\n",
            "Sample 1300: 0\n",
            "Sample 1301: 0\n",
            "Sample 1302: 0\n",
            "Sample 1303: 0\n",
            "Sample 1304: 0\n",
            "Sample 1305: 0\n",
            "Sample 1306: 0\n",
            "Sample 1307: 0\n",
            "Sample 1308: 0\n",
            "Sample 1309: 0\n",
            "Sample 1310: 0\n",
            "Sample 1311: 0\n",
            "Sample 1312: 0\n",
            "Sample 1313: 0\n",
            "Sample 1314: 0\n",
            "Sample 1315: 0\n",
            "Sample 1316: 0\n",
            "Sample 1317: 1\n",
            "Sample 1318: 0\n",
            "Sample 1319: 0\n",
            "Sample 1320: 0\n",
            "Sample 1321: 0\n",
            "Sample 1322: 0\n",
            "Sample 1323: 0\n",
            "Sample 1324: 0\n",
            "Sample 1325: 0\n",
            "Sample 1326: 0\n",
            "Sample 1327: 1\n",
            "Sample 1328: 0\n",
            "Sample 1329: 1\n",
            "Sample 1330: 1\n",
            "Sample 1331: 0\n",
            "Sample 1332: 0\n",
            "Sample 1333: 0\n",
            "Sample 1334: 1\n",
            "Sample 1335: 0\n",
            "Sample 1336: 0\n",
            "Sample 1337: 0\n",
            "Sample 1338: 0\n",
            "Sample 1339: 0\n",
            "Sample 1340: 0\n",
            "Sample 1341: 0\n",
            "Sample 1342: 0\n",
            "Sample 1343: 0\n",
            "Sample 1344: 0\n",
            "Sample 1345: 0\n",
            "Sample 1346: 0\n",
            "Sample 1347: 0\n",
            "Sample 1348: 0\n",
            "Sample 1349: 0\n",
            "Sample 1350: 0\n",
            "Sample 1351: 0\n",
            "Sample 1352: 0\n",
            "Sample 1353: 0\n",
            "Sample 1354: 0\n",
            "Sample 1355: 0\n",
            "Sample 1356: 0\n",
            "Sample 1357: 0\n",
            "Sample 1358: 1\n",
            "Sample 1359: 0\n",
            "Sample 1360: 0\n",
            "Sample 1361: 0\n",
            "Sample 1362: 0\n",
            "Sample 1363: 0\n",
            "Sample 1364: 0\n",
            "Sample 1365: 0\n",
            "Sample 1366: 0\n",
            "Sample 1367: 0\n",
            "Sample 1368: 0\n",
            "Sample 1369: 0\n",
            "Sample 1370: 0\n",
            "Sample 1371: 0\n",
            "Sample 1372: 0\n",
            "Sample 1373: 1\n",
            "Sample 1374: 0\n",
            "Sample 1375: 0\n",
            "Sample 1376: 0\n",
            "Sample 1377: 0\n",
            "Sample 1378: 0\n",
            "Sample 1379: 0\n",
            "Sample 1380: 1\n",
            "Sample 1381: 0\n",
            "Sample 1382: 0\n",
            "Sample 1383: 0\n",
            "Sample 1384: 0\n",
            "Sample 1385: 0\n",
            "Sample 1386: 0\n",
            "Sample 1387: 0\n",
            "Sample 1388: 0\n",
            "Sample 1389: 0\n",
            "Sample 1390: 1\n",
            "Sample 1391: 0\n",
            "Sample 1392: 0\n",
            "Sample 1393: 0\n",
            "Sample 1394: 0\n",
            "Sample 1395: 0\n",
            "Sample 1396: 0\n",
            "Sample 1397: 0\n",
            "Sample 1398: 0\n",
            "Sample 1399: 0\n",
            "Sample 1400: 0\n",
            "Sample 1401: 1\n",
            "Sample 1402: 0\n",
            "Sample 1403: 0\n",
            "Sample 1404: 0\n",
            "Sample 1405: 0\n",
            "Sample 1406: 0\n",
            "Sample 1407: 0\n",
            "Sample 1408: 0\n",
            "Sample 1409: 0\n",
            "Sample 1410: 0\n",
            "Sample 1411: 1\n",
            "Sample 1412: 0\n",
            "Sample 1413: 0\n",
            "Sample 1414: 0\n",
            "Sample 1415: 0\n",
            "Sample 1416: 0\n",
            "Sample 1417: 0\n",
            "Sample 1418: 0\n",
            "Sample 1419: 0\n",
            "Sample 1420: 0\n",
            "Sample 1421: 0\n",
            "Sample 1422: 0\n",
            "Sample 1423: 0\n",
            "Sample 1424: 0\n",
            "Sample 1425: 0\n",
            "Sample 1426: 0\n",
            "Sample 1427: 0\n",
            "Sample 1428: 0\n",
            "Sample 1429: 0\n",
            "Sample 1430: 0\n",
            "Sample 1431: 0\n",
            "Sample 1432: 0\n",
            "Sample 1433: 0\n",
            "Sample 1434: 0\n",
            "Sample 1435: 0\n",
            "Sample 1436: 0\n",
            "Sample 1437: 0\n",
            "Sample 1438: 0\n",
            "Sample 1439: 0\n",
            "Sample 1440: 0\n",
            "Sample 1441: 1\n",
            "Sample 1442: 0\n",
            "Sample 1443: 0\n",
            "Sample 1444: 0\n",
            "Sample 1445: 0\n",
            "Sample 1446: 0\n",
            "Sample 1447: 0\n",
            "Sample 1448: 0\n",
            "Sample 1449: 0\n",
            "Sample 1450: 0\n",
            "Sample 1451: 0\n",
            "Sample 1452: 0\n",
            "Sample 1453: 1\n",
            "Sample 1454: 0\n",
            "Sample 1455: 0\n",
            "Sample 1456: 0\n",
            "Sample 1457: 0\n",
            "Sample 1458: 0\n",
            "Sample 1459: 0\n",
            "Sample 1460: 0\n",
            "Sample 1461: 0\n",
            "Sample 1462: 0\n",
            "Sample 1463: 0\n",
            "Sample 1464: 0\n",
            "Sample 1465: 0\n",
            "Sample 1466: 0\n",
            "Sample 1467: 0\n",
            "Sample 1468: 0\n",
            "Sample 1469: 0\n",
            "Sample 1470: 0\n",
            "Sample 1471: 0\n",
            "Sample 1472: 0\n",
            "Sample 1473: 0\n",
            "Sample 1474: 0\n",
            "Sample 1475: 0\n",
            "Sample 1476: 0\n",
            "Sample 1477: 0\n",
            "Sample 1478: 0\n",
            "Sample 1479: 0\n",
            "Sample 1480: 0\n",
            "Sample 1481: 0\n",
            "Sample 1482: 0\n",
            "Sample 1483: 0\n",
            "Sample 1484: 0\n",
            "Sample 1485: 0\n",
            "Sample 1486: 0\n",
            "Sample 1487: 0\n",
            "Sample 1488: 0\n",
            "Sample 1489: 0\n",
            "Sample 1490: 0\n",
            "Sample 1491: 1\n",
            "Sample 1492: 0\n",
            "Sample 1493: 0\n",
            "Sample 1494: 0\n",
            "Sample 1495: 0\n",
            "Sample 1496: 1\n",
            "Sample 1497: 0\n",
            "Sample 1498: 0\n",
            "Sample 1499: 1\n",
            "Sample 1500: 0\n",
            "Sample 1501: 0\n",
            "Sample 1502: 0\n",
            "Sample 1503: 0\n",
            "Sample 1504: 0\n",
            "Sample 1505: 0\n",
            "Sample 1506: 0\n",
            "Sample 1507: 0\n",
            "Sample 1508: 0\n",
            "Sample 1509: 0\n",
            "Sample 1510: 0\n",
            "Sample 1511: 0\n",
            "Sample 1512: 0\n",
            "Sample 1513: 0\n",
            "Sample 1514: 0\n",
            "Sample 1515: 0\n",
            "Sample 1516: 0\n",
            "Sample 1517: 0\n",
            "Sample 1518: 0\n",
            "Sample 1519: 1\n",
            "Sample 1520: 0\n",
            "Sample 1521: 0\n",
            "Sample 1522: 0\n",
            "Sample 1523: 0\n",
            "Sample 1524: 0\n",
            "Sample 1525: 0\n",
            "Sample 1526: 0\n",
            "Sample 1527: 1\n",
            "Sample 1528: 0\n",
            "Sample 1529: 0\n",
            "Sample 1530: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now for RNN using Chatgpt 4o"
      ],
      "metadata": {
        "id": "tvfn3KfNxVd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Update the Architecture for RNN\n",
        "\n",
        "class BERT_RNN(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_RNN, self).__init__()\n",
        "\n",
        "        self.bert = bert  # Pre-trained BERT model\n",
        "        self.rnn = nn.RNN(input_size=768, hidden_size=128, batch_first=True)  # Add RNN layer\n",
        "        self.fc = nn.Linear(128, 2)  # Fully connected output layer\n",
        "        self.softmax = nn.LogSoftmax(dim=1)  # Output probabilities\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        with torch.no_grad():  # Freeze BERT parameters\n",
        "            _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        rnn_out, _ = self.rnn(cls_hs.unsqueeze(1))  # Pass embeddings through RNN\n",
        "        rnn_out = rnn_out[:, -1, :]  # Take the last output of the RNN\n",
        "        logits = self.fc(rnn_out)  # Fully connected layer\n",
        "        probs = self.softmax(logits)  # Softmax for probabilities\n",
        "        return probs\n",
        "\n",
        "# Create an instance of the model\n",
        "rnn_model = BERT_RNN(bert)\n",
        "rnn_model = rnn_model.to(device)  # Move to GPU if available\n"
      ],
      "metadata": {
        "id": "meMgIXT4wNem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Define Loss Function and Optimizer\n",
        "\n",
        "# Reuse the existing optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=1e-5)\n",
        "cross_entropy = nn.NLLLoss(weight=weights)\n"
      ],
      "metadata": {
        "id": "71EWXvDkx39n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Training Loop\n",
        "\n",
        "def train_rnn():\n",
        "    rnn_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        preds = rnn_model(sent_id, mask)  # Forward pass\n",
        "        loss = cross_entropy(preds, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 1.0)  # Clip gradients\n",
        "        optimizer.step()  # Update parameters\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n"
      ],
      "metadata": {
        "id": "iJ5LDBhrx7Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Evaluation:\n",
        "\n",
        "\n",
        "def evaluate_rnn():\n",
        "    rnn_model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = [r.to(device) for r in batch]\n",
        "            sent_id, mask, labels = batch\n",
        "            preds = rnn_model(sent_id, mask)\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    return avg_loss, np.array(all_preds)\n"
      ],
      "metadata": {
        "id": "xwEeFdiCyALQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Training and Validation\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
        "    train_loss = train_rnn()\n",
        "    valid_loss, _ = evaluate_rnn()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(rnn_model.state_dict(), 'best_rnn_model.pt')\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCn5MShQyDY8",
        "outputId": "49de1d21-6937-4c77-dee7-aac9d6957199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.669\n",
            "Validation Loss: 0.665\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.658\n",
            "Validation Loss: 0.651\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.650\n",
            "Validation Loss: 0.639\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.631\n",
            "Validation Loss: 0.632\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.618\n",
            "Validation Loss: 0.615\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.609\n",
            "Validation Loss: 0.604\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.592\n",
            "Validation Loss: 0.597\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.591\n",
            "Validation Loss: 0.588\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.579\n",
            "Validation Loss: 0.574\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.573\n",
            "Validation Loss: 0.572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Testing the RNN\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "rnn_model.load_state_dict(torch.load('best_rnn_model.pt', map_location=device, weights_only=True))\n",
        "rnn_model.eval()\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        preds = rnn_model(sent_id, mask)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "final_preds = np.argmax(all_preds, axis=1)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(classification_report(test_y, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ci-KG_uyFyQ",
        "outputId": "f611b8b6-83da-411a-8e54-547f63be5bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96      1460\n",
            "           1       0.25      0.42      0.32        71\n",
            "\n",
            "    accuracy                           0.92      1531\n",
            "   macro avg       0.61      0.68      0.64      1531\n",
            "weighted avg       0.94      0.92      0.93      1531\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now applying LSTM"
      ],
      "metadata": {
        "id": "y1X2fHv2Rf58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_LSTM(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_LSTM, self).__init__()\n",
        "        self.bert = bert  # Pre-trained BERT model\n",
        "        self.lstm = nn.LSTM(input_size=768, hidden_size=128, batch_first=True, bidirectional=False)\n",
        "        self.fc = nn.Linear(128, 2)  # Fully connected output layer\n",
        "        self.softmax = nn.LogSoftmax(dim=1)  # Softmax for output probabilities\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        with torch.no_grad():  # Freeze BERT parameters\n",
        "            _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        lstm_out, _ = self.lstm(cls_hs.unsqueeze(1))  # Pass embeddings through LSTM\n",
        "        lstm_out = lstm_out[:, -1, :]  # Take the last hidden state\n",
        "        logits = self.fc(lstm_out)\n",
        "        probs = self.softmax(logits)\n",
        "        return probs\n",
        "\n",
        "# Initialize the model\n",
        "lstm_model = BERT_LSTM(bert)\n",
        "lstm_model = lstm_model.to(device)  # Move to GPU if available\n"
      ],
      "metadata": {
        "id": "bbeZw_7JRcLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(lstm_model.parameters(), lr=1e-5)\n",
        "cross_entropy = nn.NLLLoss(weight=weights)\n"
      ],
      "metadata": {
        "id": "1xtGMzGvRmwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm():\n",
        "    lstm_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        preds = lstm_model(sent_id, mask)  # Forward pass\n",
        "        loss = cross_entropy(preds, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(lstm_model.parameters(), 1.0)  # Clip gradients\n",
        "        optimizer.step()  # Update parameters\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n"
      ],
      "metadata": {
        "id": "HwDQa-sqRpnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_lstm():\n",
        "    lstm_model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = [r.to(device) for r in batch]\n",
        "            sent_id, mask, labels = batch\n",
        "            preds = lstm_model(sent_id, mask)\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    return avg_loss, np.array(all_preds)\n"
      ],
      "metadata": {
        "id": "o7RSYbDBRtIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(10):  # Adjust epochs as needed\n",
        "    print(f'\\n Epoch {epoch + 1} / 10')\n",
        "    train_loss = train_lstm()\n",
        "    valid_loss, _ = evaluate_lstm()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(lstm_model.state_dict(), 'best_lstm_model.pt')\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4SkF6VRwVJ",
        "outputId": "4313700f-b079-4324-96a6-c0e3957f4f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.669\n",
            "Validation Loss: 0.670\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 0.660\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.648\n",
            "Validation Loss: 0.651\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.639\n",
            "Validation Loss: 0.639\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.633\n",
            "Validation Loss: 0.628\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.617\n",
            "Validation Loss: 0.620\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.609\n",
            "Validation Loss: 0.611\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 0.602\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.602\n",
            "Validation Loss: 0.587\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Training Loss: 0.589\n",
            "Validation Loss: 0.580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.load_state_dict(torch.load('best_lstm_model.pt'))\n",
        "lstm_model.eval()\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        preds = lstm_model(sent_id, mask)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "final_preds = np.argmax(all_preds, axis=1)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(classification_report(test_y, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar_Lr5rzR8SA",
        "outputId": "9d5c5983-9fc9-4e90-84b5-dc04a6df65ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-5ab05b82a2c6>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lstm_model.load_state_dict(torch.load('best_lstm_model.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95      1460\n",
            "           1       0.25      0.46      0.33        71\n",
            "\n",
            "    accuracy                           0.91      1531\n",
            "   macro avg       0.61      0.70      0.64      1531\n",
            "weighted avg       0.94      0.91      0.92      1531\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def compute_metrics_from_report(model, test_dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    # Disable gradient computation\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            batch = [r.to(device) for r in batch]\n",
        "            #seq,labels = batch\n",
        "            sent_id,mask,labels = batch\n",
        "\n",
        "            # Model predictions\n",
        "            preds = model(sent_id,mask)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Extract predictions and true labels\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            all_preds.extend(np.argmax(preds, axis=1))\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    precision = report['weighted avg']['precision']\n",
        "    recall = report['weighted avg']['recall']\n",
        "    f1 = report['weighted avg']['f1-score']\n",
        "    avg_loss = total_loss / len(test_dataloader)\n",
        "\n",
        "    return accuracy, precision, recall, f1, avg_loss\n",
        "\n",
        "# Extract metrics for Text2Vec + RNN\n",
        "rnn_metrics = compute_metrics_from_report(rnn_model, test_dataloader)\n",
        "print(\"Text2Vec + RNN Metrics:\")\n",
        "print(f\"Accuracy: {rnn_metrics[0]:.4f}\")\n",
        "print(f\"Precision: {rnn_metrics[1]:.4f}\")\n",
        "print(f\"Recall: {rnn_metrics[2]:.4f}\")\n",
        "print(f\"F1-Score: {rnn_metrics[3]:.4f}\")\n",
        "print(f\"Loss Value: {rnn_metrics[4]:.4f}\")\n",
        "\n",
        "# Extract metrics for Text2Vec + LSTM\n",
        "lstm_metrics = compute_metrics_from_report(lstm_model, test_dataloader)\n",
        "print(\"\\nText2Vec + LSTM Metrics:\")\n",
        "print(f\"Accuracy: {lstm_metrics[0]:.4f}\")\n",
        "print(f\"Precision: {lstm_metrics[1]:.4f}\")\n",
        "print(f\"Recall: {lstm_metrics[2]:.4f}\")\n",
        "print(f\"F1-Score: {lstm_metrics[3]:.4f}\")\n",
        "print(f\"Loss Value: {lstm_metrics[4]:.4f}\")\n",
        "\n",
        "# Create a table to compare results\n",
        "import pandas as pd\n",
        "\n",
        "comparison_table = pd.DataFrame({\n",
        "    \"Metric\": [\"Test Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Loss Value\"],\n",
        "    \"Text2Vec + RNN\":rnn_metrics,\n",
        "    \"Text2Vec + LSTM\":lstm_metrics\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "print(\"\\nComparison Table:\")\n",
        "print(comparison_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvwvDIxbShdY",
        "outputId": "1587dc2e-aef6-4183-d7c5-10ff747811dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text2Vec + RNN Metrics:\n",
            "Accuracy: 0.9157\n",
            "Precision: 0.9377\n",
            "Recall: 0.9157\n",
            "F1-Score: 0.9255\n",
            "Loss Value: 0.5497\n",
            "\n",
            "Text2Vec + LSTM Metrics:\n",
            "Accuracy: 0.9105\n",
            "Precision: 0.9393\n",
            "Recall: 0.9105\n",
            "F1-Score: 0.9230\n",
            "Loss Value: 0.5573\n",
            "\n",
            "Comparison Table:\n",
            "          Metric  Text2Vec + RNN  Text2Vec + LSTM\n",
            "0  Test Accuracy        0.915741         0.910516\n",
            "1      Precision        0.937745         0.939316\n",
            "2         Recall        0.915741         0.910516\n",
            "3       F1-Score        0.925529         0.923006\n",
            "4     Loss Value        0.549704         0.557311\n"
          ]
        }
      ]
    }
  ]
}